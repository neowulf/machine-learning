{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T22:54:12.322759Z",
     "start_time": "2017-12-15T22:53:53.654923Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Allows for interactive shell - outputs all non variable statements\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T22:54:12.336625Z",
     "start_time": "2017-12-15T22:54:12.324649Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "np.random.seed(10)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "DATASET_DIR=os.path.join(current_dir, 'dataset')\n",
    "CROSSVALID_DIR=os.path.join(DATASET_DIR, 'cross_valid')\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATASET_DIR, 'test')\n",
    "CROSSVALID_DIR = os.path.join(DATASET_DIR, 'cross_valid')\n",
    "SAMPLE_DIR = os.path.join(DATASET_DIR, 'sample')\n",
    "\n",
    "WEIGHTS_DIR = os.path.join(current_dir, 'weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Keras Vgg16 to get the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download the dataset in the current directory.\n",
    "```\n",
    "kg download -c 'dogs-vs-cats-redux-kernels-edition'\n",
    "```\n",
    "* Inspect the data\n",
    "* Prepare a single image\n",
    "* Feed it into pretrained vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inspect the data\n",
    "\n",
    "Graph the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T03:13:52.340870Z",
     "start_time": "2017-12-15T03:13:51.603386Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Unzip a single file to test on the pretrained model\n",
    "!unzip -oj \"test.zip\" \"test/1.jpg\" -d \"/tmp/cats_dogs\"\n",
    "\n",
    "# Load the image\n",
    "img_path = '/tmp/cats_dogs/1.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# Plot the single image\n",
    "f = plt.figure(figsize=(10, 5))\n",
    "sp = f.add_subplot(1, 1, 1) ## (rows, cols, index)\n",
    "sp.axis('On')\n",
    "sp.set_title(img_path, fontsize=16)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using Keras Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T03:55:04.850974Z",
     "start_time": "2017-12-15T03:55:04.780879Z"
    }
   },
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "preds = model.predict(x)\n",
    "decode_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T03:18:50.554332Z",
     "start_time": "2017-12-15T03:18:50.490446Z"
    }
   },
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)\n",
    "decode_predictions(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare dataset\n",
    "    1. Download the dataset\n",
    "    1. Unzip training and test dataset\n",
    "    1. Create the training, validation, sample batch dataset\n",
    "    1. Create the labels\n",
    "1. Model preparation\n",
    "    1. Finetune the keras model\n",
    "       1. Pop the last layer, freeze all layers, add a softmax layer and update set of classes\n",
    "    1. Fit the keras model\n",
    "       1. Train the updated keras model\n",
    "    1. Save and load the model after couple of epochs\n",
    "1. Perform predictions\n",
    "1. Debug\n",
    "   1. View the confusion matrix\n",
    "   1. Visual Inspection\n",
    "       1. Inspect correct labels\n",
    "       1. Inspect incorrect labels\n",
    "       1. Inspect correct labels with high probability\n",
    "       1. Inspect incorrect label with high probability\n",
    "       1. Inspect correct labels with medium probability\n",
    "1. Kaggle Submission\n",
    "    1. Prepare csv file\n",
    "    1. Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune the keras model\n",
    "* Pop the last layer, freeze all layers, add a softmax layer and update set of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T22:55:36.047530Z",
     "start_time": "2017-12-15T22:55:32.114885Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "ttl_outputs = 2\n",
    "learning_rate = 0.01\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "inputs = base_model.input\n",
    "outputs = Dense(ttl_outputs, activation='softmax')(base_model.output)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(lr = learning_rate), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and save the keras model\n",
    "\n",
    "* Train the updated keras model with the new data for couple of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T03:56:19.143003Z",
     "start_time": "2017-12-15T03:55:59.786290Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "batch_size = 4\n",
    "epochs = 3\n",
    "train_dir = SAMPLE_DIR + '/train'\n",
    "crossvalid_dir = SAMPLE_DIR + '/cross_valid'\n",
    "\n",
    "nb_train_samples = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
    "nb_validation_samples = sum([len(files) for r, d, files in os.walk(crossvalid_dir)])\n",
    "\n",
    "def process_img(img_np):\n",
    "    #print(img_path.shape)\n",
    "    #img = image.load_img(img_path, target_size=(224,244))\n",
    "    #f = img.img_to_array(img)\n",
    "    f = np.expand_dims(img_np, axis=0)\n",
    "    f = preprocess_input(f)\n",
    "    return f\n",
    "\n",
    "# datagen = ImageDataGenerator(preprocessing_function=process_img)\n",
    "datagen = ImageDataGenerator(\n",
    "    data_format='channels_last',\n",
    "    preprocessing_function=process_img)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    crossvalid_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "# add preprocessing to the image?\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T03:57:28.435431Z",
     "start_time": "2017-12-15T03:56:29.306057Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = list(iter(train_generator.class_indices))\n",
    "for c in train_generator.class_indices:\n",
    "    classes[train_generator.class_indices[c]] = c\n",
    "\n",
    "train_generator.class_indices\n",
    "classes\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "    os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "    model.save_weights(os.path.join(WEIGHTS_DIR, 'intial_sample_run_{}.h5'.format(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T04:00:21.775137Z",
     "start_time": "2017-12-15T04:00:19.740510Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(WEIGHTS_DIR, 'intial_sample_run_2.h5'))\n",
    "\n",
    "def get_data_as_np(path, batch_size=5):\n",
    "    batches = datagen.flow_from_directory(\n",
    "        path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=10,\n",
    "        class_mode=None,\n",
    "        shuffle=False\n",
    "    )\n",
    "    return np.concatenate([batches.next() for i in range(len(batches))])\n",
    "\n",
    "model.predict(get_data_as_np(crossvalid_dir, 5), batch_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-15T03:58:10.725220Z",
     "start_time": "2017-12-15T03:58:10.719107Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_batches = self.get_batches(path, shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "test_batches, self.model.predict_generator(test_batches, test_batches.nb_sample)\n",
    "\n",
    "preds[1:4]\n",
    "preds.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "669px",
    "left": "1336px",
    "right": "68.4167px",
    "top": "96.1167px",
    "width": "330px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
